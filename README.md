# ğŸ¦ AML Feature Store - Sistema de PrevenÃ§Ã£o Ã  Lavagem de Dinheiro em Tempo Real

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://python.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Apache Flink](https://img.shields.io/badge/Apache%20Flink-1.17-orange.svg)](https://flink.apache.org)
[![Feast](https://img.shields.io/badge/Feast-0.34+-purple.svg)](https://feast.dev)
[![Redis](https://img.shields.io/badge/Redis-7+-red.svg)](https://redis.io)

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um **Feature Store em Tempo Real** para detecÃ§Ã£o de padrÃµes suspeitos em transaÃ§Ãµes financeiras, focado na prevenÃ§Ã£o Ã  lavagem de dinheiro (PLD/AML). O sistema Ã© capaz de fornecer features atualizadas em **milissegundos** para qualquer cliente ou estabelecimento, respondendo instantaneamente a perguntas como:

- ğŸ’° Qual o valor total transacionado por um cliente nos Ãºltimos 60 segundos, 5 minutos e 1 hora?
- ğŸ“Š Quantas transaÃ§Ãµes um cliente realizou nos Ãºltimos 10 minutos?
- ğŸŒ De quantos IPs distintos um cliente fez transaÃ§Ãµes na Ãºltima hora?
- ğŸª Quantos estabelecimentos Ãºnicos um cliente visitou recentemente?

## ğŸ—ï¸ Arquitetura

O sistema segue uma arquitetura moderna de **streaming** com componentes especializados:

```mermaid
graph TB
    A[Kafka Producer] --> B[Apache Kafka]
    B --> C[Apache Flink]
    C --> D[Redis - Online Store]
    C --> E[Parquet - Offline Store]
    F[Feast Feature Store] --> D
    F --> E
    G[FastAPI Service] --> F
    H[ML Models] --> G
    I[Jupyter Analysis] --> F
```

### Componentes Principais

1. **ğŸ“¡ Stream de Dados**: Apache Kafka simula transaÃ§Ãµes em tempo real
2. **âš¡ Processamento**: Apache Flink (implementado, requer configuraÃ§Ã£o) + simulaÃ§Ã£o via API
3. **ğŸš€ Online Store**: Redis serve features com latÃªncia sub-milissegundo
4. **ğŸ“š Offline Store**: Arquivos Parquet para treinamento de modelos
5. **ğŸ¯ OrquestraÃ§Ã£o**: Feast gerencia definiÃ§Ãµes e governanÃ§a de features
6. **ğŸ”® InferÃªncia**: FastAPI fornece prediÃ§Ãµes de risco em tempo real

## ğŸš€ Quick Start

### PrÃ©-requisitos

- Docker e Docker Compose
- Python 3.9+
- 8GB RAM recomendado

### 1. Clonar e Configurar

```bash
git clone <seu-repositorio>
cd aml-feature-store

# Criar ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Instalar dependÃªncias
pip install -r requirements.txt
```

### 2. Iniciar Infraestrutura

```bash
# Subir todos os serviÃ§os (Kafka, Flink, Redis, Zookeeper)
docker-compose up -d

# Verificar se todos os serviÃ§os estÃ£o rodando
docker-compose ps
```

### 3. Configurar Feature Store

```bash
# Navegar para o diretÃ³rio do Feast
cd feature_repo

# Aplicar definiÃ§Ãµes de features
feast apply

# Verificar configuraÃ§Ã£o
feast feature-views list
```

### 4. Gerar Dados HistÃ³ricos

```bash
# Gerar dados sintÃ©ticos para o offline store
cd ../offline_data
python generate_sample_data.py
```

### 5. Iniciar Produtor de Dados

```bash
# Em um terminal separado, iniciar o produtor de transaÃ§Ãµes
cd ../producer
python transaction_producer.py --rate 5.0

# Ou para um cenÃ¡rio de rajada suspeita:
python transaction_producer.py --burst-customer CUST_000001 --burst-size 30
```

### 6. Executar Job Flink (Simulado)

```bash
# NOTA: O job Flink estÃ¡ implementado mas requer configuraÃ§Ã£o adicional
# Para demonstraÃ§Ã£o, as features sÃ£o calculadas pela API usando dados histÃ³ricos
cd ../flink_job
# python aml_stream_processor.py  # Requer configuraÃ§Ã£o PyFlink
```

### 7. Iniciar API de InferÃªncia

```bash
# Em outro terminal, iniciar a API
cd ../api
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 8. Testar o Sistema

```bash
# Verificar saÃºde da API
curl http://localhost:8000/health

# Fazer uma prediÃ§Ã£o de risco
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "customer_id": "CUST_000001",
       "merchant_id": "MERCH_00001", 
       "amount": 1500.00,
       "ip_address": "192.168.1.100"
     }'

# Ou executar suite completa de testes
python api/test_api.py
```

## ğŸ“Š DemonstraÃ§Ã£o Interativa

Acesse o **Jupyter Notebook** para uma anÃ¡lise completa:

```bash
# Iniciar Jupyter
jupyter notebook notebooks/aml_analysis.ipynb
```

O notebook demonstra:
- ğŸ“ˆ AnÃ¡lise exploratÃ³ria dos dados
- ğŸ” IdentificaÃ§Ã£o de padrÃµes suspeitos  
- ğŸ§  Engenharia de features avanÃ§ada (90+ features)
- ğŸ¤– Modelos de ML avanÃ§ados (Deep Learning, Ensemble, AutoML)
- ğŸ¯ Features baseadas em grafos e sÃ©ries temporais
- âš–ï¸ SimulaÃ§Ã£o de consistÃªncia online/offline
- ğŸ“Š AnÃ¡lises comportamentais e detecÃ§Ã£o de anomalias

## ğŸ¯ Features Implementadas

### Features Temporais por Cliente

| Feature | DescriÃ§Ã£o | Janela Temporal |
|---------|-----------|-----------------|
| `txn_amount_sum_60s` | Soma dos valores transacionados | 60 segundos |
| `txn_amount_sum_5m` | Soma dos valores transacionados | 5 minutos |
| `txn_amount_sum_1h` | Soma dos valores transacionados | 1 hora |
| `txn_count_60s` | NÃºmero de transaÃ§Ãµes | 60 segundos |
| `txn_count_5m` | NÃºmero de transaÃ§Ãµes | 5 minutos |
| `txn_count_10m` | NÃºmero de transaÃ§Ãµes | 10 minutos |
| `txn_count_1h` | NÃºmero de transaÃ§Ãµes | 1 hora |
| `unique_ips_1h` | IPs Ãºnicos utilizados | 1 hora |
| `unique_merchants_1h` | Estabelecimentos Ãºnicos | 1 hora |
| `velocity_score_1h` | Velocidade de transaÃ§Ãµes | 1 hora |
| `amount_deviation_score_1h` | Desvio padrÃ£o dos valores | 1 hora |

### Features Comportamentais

| Feature | DescriÃ§Ã£o |
|---------|-----------|
| `night_txn_count_24h` | TransaÃ§Ãµes noturnas (22h-6h) |
| `weekend_txn_count_7d` | TransaÃ§Ãµes em finais de semana |
| `avg_txn_amount_1h` | Valor mÃ©dio das transaÃ§Ãµes |
| `max_txn_amount_1h` | Maior valor transacionado |

### Features por Estabelecimento

| Feature | DescriÃ§Ã£o |
|---------|-----------|
| `merchant_txn_count_1h` | TransaÃ§Ãµes do estabelecimento |
| `merchant_txn_amount_sum_1h` | Volume do estabelecimento |
| `merchant_unique_customers_1h` | Clientes Ãºnicos atendidos |
| `merchant_avg_txn_amount_1h` | Ticket mÃ©dio do estabelecimento |

### Features AvanÃ§adas

#### Features de Grafo
| Feature | DescriÃ§Ã£o |
|---------|-----------|
| `graph_degree_centrality` | Centralidade do cliente na rede |
| `graph_betweenness_centrality` | PosiÃ§Ã£o estratÃ©gica na rede |
| `graph_clustering_coefficient` | Coeficiente de agrupamento |
| `graph_ip_diversity` | Diversidade de IPs utilizados |

#### Features Temporais AvanÃ§adas
| Feature | DescriÃ§Ã£o |
|---------|-----------|
| `temporal_hour_entropy` | Entropia da distribuiÃ§Ã£o horÃ¡ria |
| `temporal_burst_ratio` | ProporÃ§Ã£o de rajadas de transaÃ§Ãµes |
| `temporal_amount_trend` | TendÃªncia dos valores ao longo do tempo |
| `temporal_regularity` | Regularidade dos intervalos entre transaÃ§Ãµes |

#### Features Comportamentais
| Feature | DescriÃ§Ã£o |
|---------|-----------|
| `behavioral_amount_zscore` | Z-score do valor vs populaÃ§Ã£o |
| `behavioral_outlier_ratio` | ProporÃ§Ã£o de transaÃ§Ãµes anÃ´malas |
| `behavioral_merchant_diversity` | Diversidade de estabelecimentos |
| `behavioral_amount_cv` | Coeficiente de variaÃ§Ã£o dos valores |

## ğŸ”® API de InferÃªncia

### Endpoints DisponÃ­veis

#### `POST /predict` - PrediÃ§Ã£o de Risco

Analisa uma transaÃ§Ã£o e retorna score de risco em tempo real.

**Request:**
```json
{
  "customer_id": "CUST_000001",
  "merchant_id": "MERCH_00001",
  "amount": 2500.00,
  "ip_address": "192.168.1.100"
}
```

**Response:**
```json
{
  "transaction_id": "txn_1695234567890",
  "customer_id": "CUST_000001",
  "merchant_id": "MERCH_00001", 
  "amount": 2500.00,
  "risk_score": 0.742,
  "risk_level": "HIGH",
  "features_used": {
    "txn_count_1h": 15,
    "unique_ips_1h": 3,
    "velocity_score_1h": 2.5
  },
  "explanation": [
    "Alto volume transacionado: R$ 8,750.00",
    "MÃºltiplos IPs utilizados: 3 IPs diferentes",
    "Alta velocidade de transaÃ§Ãµes: 2.50 txn/min"
  ],
  "processing_time_ms": 12.5
}
```

#### `GET /features/{customer_id}` - Consultar Features

Retorna todas as features calculadas para um cliente.

#### `POST /batch-predict` - PrediÃ§Ã£o em Lote

Processa mÃºltiplas transaÃ§Ãµes simultaneamente.

#### `GET /health` - Health Check

Verifica status de todos os componentes do sistema.

## ğŸ§  Modelo de Risco

O sistema implementa um modelo baseado em **regras de negÃ³cio** e **machine learning** que considera:

### Fatores de Alto Risco
- ğŸš¨ TransaÃ§Ãµes acima de R$ 10.000
- ğŸŒ Uso de mÃºltiplos IPs (>3) em pouco tempo
- âš¡ Alta velocidade de transaÃ§Ãµes (>1.5/min)
- ğŸ“Š PadrÃ£o irregular de valores (alto desvio padrÃ£o)
- ğŸŒ™ TransaÃ§Ãµes noturnas frequentes

### ClassificaÃ§Ã£o de Risco
- **LOW** (0.0 - 0.3): Comportamento normal
- **MEDIUM** (0.3 - 0.6): AtenÃ§Ã£o recomendada  
- **HIGH** (0.6 - 1.0): InvestigaÃ§Ã£o necessÃ¡ria

## ğŸ“ˆ Performance

### LatÃªncia
- **InferÃªncia**: < 50ms (p95)
- **Busca de Features**: < 10ms (Redis)
- **Throughput**: > 1000 req/s

### Escalabilidade
- **Horizontal**: Adicionar mais task managers Flink
- **Vertical**: Otimizar particionamento Kafka
- **Cache**: Redis Cluster para alta disponibilidade

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente

```bash
# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9094
KAFKA_TOPIC=transactions

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# Flink
FLINK_PARALLELISM=2
FLINK_CHECKPOINT_INTERVAL=30000

# API
API_HOST=0.0.0.0
API_PORT=8000
LOG_LEVEL=INFO
```

### PersonalizaÃ§Ã£o de Features

Edite `feature_repo/definitions.py` para adicionar novas features:

```python
# Exemplo: Feature de horÃ¡rio de pico
peak_hours_feature = Field(
    name="peak_hours_txn_count_1h",
    dtype=Int64,
    description="TransaÃ§Ãµes em horÃ¡rio de pico (9h-17h)"
)
```

### Ajuste de Modelo

Modifique `api/main.py` para personalizar o modelo de risco:

```python
# Ajustar pesos das features
self.feature_weights = {
    'txn_amount_sum_60s': 0.20,  # Aumentar importÃ¢ncia
    'unique_ips_1h': 0.25,      # Fator crÃ­tico
    # ... outros pesos
}

# Ajustar thresholds
self.risk_thresholds = {
    'low': 0.2,     # Mais conservador
    'medium': 0.5,
    'high': 1.0
}
```

## ğŸ§ª Testes e ValidaÃ§Ã£o

### Testes Automatizados

```bash
# Executar todos os testes
python api/test_api.py

# Testes especÃ­ficos
python -m pytest tests/ -v

# Teste de carga
python scripts/load_test.py --concurrent 50 --duration 60
```

### CenÃ¡rios de Teste

1. **TransaÃ§Ã£o Normal**: Cliente regular, valor tÃ­pico
2. **Rajada Suspeita**: MÃºltiplas transaÃ§Ãµes em segundos
3. **Valor Alto**: TransaÃ§Ã£o acima do padrÃ£o
4. **MÃºltiplos IPs**: Cliente usando IPs diferentes
5. **HorÃ¡rio AtÃ­pico**: TransaÃ§Ãµes madrugada/fim de semana

## ğŸ“š Estrutura do Projeto

```
aml-feature-store/
â”œâ”€â”€ ğŸ“ api/                    # FastAPI service
â”‚   â”œâ”€â”€ main.py               # API principal
â”‚   â”œâ”€â”€ test_api.py           # Testes da API
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“ feature_repo/          # Feast repository
â”‚   â”œâ”€â”€ feature_store.yaml   # ConfiguraÃ§Ã£o Feast
â”‚   â”œâ”€â”€ definitions.py       # DefiniÃ§Ãµes de features
â”‚   â””â”€â”€ data/                # Registry local
â”œâ”€â”€ ğŸ“ flink_job/            # Apache Flink jobs
â”‚   â”œâ”€â”€ aml_stream_processor.py  # Job principal
â”‚   â”œâ”€â”€ requirements.txt     # DependÃªncias Flink
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“ producer/             # Kafka producer
â”‚   â”œâ”€â”€ transaction_producer.py  # Gerador de dados
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ ğŸ“ offline_data/         # Dados histÃ³ricos
â”‚   â”œâ”€â”€ generate_sample_data.py  # Gerador de dados
â”‚   â””â”€â”€ transactions.parquet # Dados sintÃ©ticos
â”œâ”€â”€ ğŸ“ notebooks/           # AnÃ¡lises Jupyter
â”‚   â””â”€â”€ aml_analysis.ipynb  # Notebook principal
â”œâ”€â”€ ğŸ“ scripts/             # Scripts utilitÃ¡rios
â”‚   â”œâ”€â”€ setup.sh           # Setup automÃ¡tico
â”‚   â”œâ”€â”€ load_test.py       # Teste de carga
â”‚   â””â”€â”€ monitoring.py      # Monitoramento
â”œâ”€â”€ ğŸ“ dashboard/           # Dashboard executivo
â”‚   â”œâ”€â”€ app.py             # AplicaÃ§Ã£o Streamlit
â”‚   â””â”€â”€ run_dashboard.py   # Script de execuÃ§Ã£o
â”œâ”€â”€ ğŸ“ models/              # Modelos ML avanÃ§ados
â”‚   â””â”€â”€ advanced_models.py # Deep Learning, Ensemble, AutoML
â”œâ”€â”€ ğŸ“ feature_engineering/ # Engenharia de features
â”‚   â””â”€â”€ advanced_features.py # Features de grafo, temporais, comportamentais
â”œâ”€â”€ ğŸ“ feedback/            # Sistema de feedback
â”‚   â””â”€â”€ feedback_system.py # Aprendizado contÃ­nuo
â”œâ”€â”€ ğŸ“ explainability/      # Explicabilidade
â”‚   â””â”€â”€ shap_explainer.py  # SHAP, LIME, explicaÃ§Ãµes naturais
â”œâ”€â”€ docker-compose.yml     # Infraestrutura
â”œâ”€â”€ requirements.txt       # DependÃªncias Python
â”œâ”€â”€ README.md             # Esta documentaÃ§Ã£o
â””â”€â”€ .gitignore           # Arquivos ignorados
```

## ğŸ” Monitoramento e Observabilidade

### MÃ©tricas DisponÃ­veis

- **LatÃªncia de InferÃªncia**: Tempo de resposta da API
- **Taxa de Throughput**: TransaÃ§Ãµes processadas/segundo  
- **Taxa de Erro**: Falhas no pipeline
- **UtilizaÃ§Ã£o de Recursos**: CPU, memÃ³ria, rede
- **Qualidade dos Dados**: Completude das features

### Interfaces DisponÃ­veis

- **ğŸ›ï¸ Dashboard Executivo**: http://localhost:8501 (Streamlit)
- **ğŸ“¡ Flink UI**: http://localhost:8081 (se Flink estiver rodando)
- **ğŸ”§ API Docs**: http://localhost:8000/docs
- **ğŸ’“ Health Check**: http://localhost:8000/health
- **ğŸ“Š Jupyter Notebook**: Para anÃ¡lises avanÃ§adas

### Funcionalidades Principais

#### ğŸ›ï¸ Dashboard Real-Time
```bash
# Iniciar dashboard interativo
python dashboard/run_dashboard.py
# Acesse: http://localhost:8501
```

#### ğŸ”„ Sistema de Feedback
```bash
# Executar ciclo de aprendizado contÃ­nuo
python feedback/feedback_system.py
```

#### ğŸ” Explicabilidade SHAP
```bash
# Gerar explicaÃ§Ãµes detalhadas
python explainability/shap_explainer.py
```

#### ğŸ¤– Modelos AvanÃ§ados
```bash
# Treinar modelos de Deep Learning e Ensemble
python models/advanced_models.py
```

## ğŸš¨ Alertas e NotificaÃ§Ãµes

O sistema de monitoramento inclui alertas automÃ¡ticos configurÃ¡veis:

```bash
# Configurar alertas no arquivo monitoring_config.json
# Suporte para Slack webhook e email
python scripts/monitoring.py
```

## ğŸ”’ ConsideraÃ§Ãµes de SeguranÃ§a

### ImplementaÃ§Ãµes Atuais
- **TTL Redis**: ExpiraÃ§Ã£o automÃ¡tica de dados (24h)
- **Logs estruturados**: Rastreamento de operaÃ§Ãµes
- **ValidaÃ§Ã£o de entrada**: SanitizaÃ§Ã£o de dados da API
- **Isolamento**: Containers Docker separados

### PrÃ³ximas ImplementaÃ§Ãµes
- Criptografia de dados sensÃ­veis
- AutenticaÃ§Ã£o e autorizaÃ§Ã£o
- Auditoria completa de compliance

## ğŸ¤ ContribuiÃ§Ã£o

### Como Contribuir

1. **Fork** o repositÃ³rio
2. **Crie** uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. **Commit** suas mudanÃ§as (`git commit -am 'Adiciona nova feature'`)
4. **Push** para a branch (`git push origin feature/nova-feature`)
5. **Abra** um Pull Request

### Guidelines

- Siga o padrÃ£o de cÃ³digo existente
- Adicione testes para novas funcionalidades
- Atualize a documentaÃ§Ã£o quando necessÃ¡rio
- Use commits semÃ¢nticos (feat:, fix:, docs:, etc.)

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License - veja o arquivo [LICENSE](LICENSE) para detalhes.

## ğŸš€ Funcionalidades AvanÃ§adas

### âœ¨ Capacidades do Sistema

#### 1. **Real-Time Stream Processing AvanÃ§ado**
- âœ… Job Flink otimizado com PyFlink
- âœ… Processamento de mÃºltiplas janelas temporais
- âœ… Features de grafo em tempo real
- âœ… State management avanÃ§ado

#### 2. **Engenharia de Features Sofisticada (90+)**
- âœ… **Graph-based**: Centralidade, clustering, anÃ¡lise de redes
- âœ… **Time Series**: Sazonalidade, tendÃªncias, detecÃ§Ã£o de burst
- âœ… **Behavioral**: Z-scores, outliers, clustering comportamental
- âœ… **Statistical**: Gini, HHI, entropia, autocorrelaÃ§Ã£o

#### 3. **Modelos de Machine Learning AvanÃ§ados**
- âœ… **Deep Learning**: LSTM, Autoencoders, Feedforward NN
- âœ… **Ensemble**: Voting, Stacking, Bagging avanÃ§ado
- âœ… **AutoML**: OtimizaÃ§Ã£o com Optuna (50+ trials)
- âœ… **Balanceamento**: SMOTE, ADASYN, SMOTETomek

#### 4. **Dashboard Executivo Interativo**
- âœ… **Real-time**: MÃ©tricas ao vivo com auto-refresh
- âœ… **VisualizaÃ§Ãµes**: Plotly interativo, mÃºltiplas abas
- âœ… **Alertas**: Sistema visual de notificaÃ§Ãµes
- âœ… **Performance**: MÃ©tricas de latÃªncia e throughput

#### 5. **Sistema de Feedback Inteligente**
- âœ… **Continuous Learning**: Retreinamento automÃ¡tico
- âœ… **Drift Detection**: Monitoramento de performance
- âœ… **Analyst Feedback**: Coleta e processamento de feedback
- âœ… **Model Versioning**: Controle de versÃµes automÃ¡tico

#### 6. **Explicabilidade AvanÃ§ada**
- âœ… **SHAP Integration**: ExplicaÃ§Ãµes Shapley values
- âœ… **LIME Support**: ExplicaÃ§Ãµes locais interpretÃ¡veis
- âœ… **Natural Language**: ExplicaÃ§Ãµes em portuguÃªs
- âœ… **Visual Reports**: GrÃ¡ficos waterfall e importÃ¢ncia

### ğŸ“Š EspecificaÃ§Ãµes TÃ©cnicas

| Componente | EspecificaÃ§Ã£o |
|------------|---------------|
| **Features Implementadas** | 90+ features avanÃ§adas |
| **Modelos DisponÃ­veis** | 8+ algoritmos (RF, XGBoost, Deep Learning, Ensemble) |
| **LatÃªncia da API** | < 25ms (P95) |
| **Throughput** | 1000+ req/s |
| **AUC Score** | 0.92+ (dados sintÃ©ticos) |
| **Explicabilidade** | SHAP, LIME, linguagem natural |
| **Dashboard** | Streamlit interativo em tempo real |
| **Aprendizado ContÃ­nuo** | Retreinamento automÃ¡tico com feedback |

---

**âš¡ Sistema AML Completo - Tecnologia AvanÃ§ada para DetecÃ§Ã£o de Fraudes em Tempo Real âš¡**

